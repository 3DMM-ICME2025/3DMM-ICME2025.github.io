<!DOCTYPE html>
<html lang="en">

<head>
    <title>3DMM</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

 
    <link rel="icon" type="image/x-ico" href="imgs/logo.png" />
    

    <link href="https://fonts.googleapis.com/css?family=B612+Mono|Cabin:400,700&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="fonts/icomoon/style.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
          integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">

    <link rel="stylesheet" href="css/jquery-ui.css">
    <link rel="stylesheet" href="css/owl.carousel.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">

    <link rel="stylesheet" href="css/jquery.fancybox.min.css">

    <link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">

    <link rel="stylesheet" href="css/aos.css">
    <link href="css/jquery.mb.YTPlayer.min.css" media="all" rel="stylesheet" type="text/css">

    <link rel="stylesheet" href="css/style.css">



    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-88572407-1', 'auto');
        ga('send', 'pageview');
    </script>
</head>

<body data-spy="scroll" data-target=".site-navbar-target" data-offset="300">



<div class="site-wrap">

    <div class="site-mobile-menu site-navbar-target">
        <div class="site-mobile-menu-header">

            <div class="site-mobile-menu-close mt-3">
                <span class="icon-close2 js-menu-toggle"></span>
            </div>
        </div>
        <div class="site-mobile-menu-body"></div>
    </div>

<!---------------------------导航栏------------------------------->
    <div class="site-navbar py-2 js-sticky-header site-navbar-target d-none pl-0 d-lg-block" role="banner" > 


            <div class="d-flex align-items-center">
             

                <div class="mr-auto">

               
                    <nav class="site-navigation position-relative text-right" role="navigation">
                     <a href="http://iccv2021.thecvf.com/"> <img class='iccv' src="imgs/icme.png" width=190px height=47px style="margin-top:-1px;"></a>

               

                        <ul class="site-menu main-menu js-clone-nav mr-auto d-none pl-0 d-lg-block">
                            <li>
                           
                                <a href="index.html"><img src="imgs/logo.png" width=190px height=47px style="margin-left: 200px; margin-top: -3.5px; position: sticky;"></a>
                            </li>
                            <li>
                                
                                <a href="index.html" class="nav-link text-left" style="font-size:15px; font-family:Georgia, serif;">Home</a>
                            </li>
                            
                            <li>
                                <a href="index.html#call for papers" class="nav-link text-left" style="font-size:15px; font-family:Georgia, serif">Call for papers</a>
                            </li>

                            <li>
                                <a href="index.html#dates" class="nav-link text-left" style="font-size:15px; font-family:Georgia, serif">important dates</a>
                            </li>

                            <li>
                                <a href="index.html#invited speakers" class="nav-link text-left" style="font-size:15px; font-family:Georgia, serif">invited speakers</a>
                            </li>



                            <li>
                                <a href="index.html#organizers" class="nav-link text-left" style="font-size:15px; font-family:Georgia, serif">organizers</a>
                            </li>


                            </li>
                        </ul>
                    </nav>

                </div>

            </div>
        </div>

    </div>

</div>

<div class="site-blocks-cover overlay inner-page-cover" style="background-image: url('imgs/background.png');" 


     data-stellar-background-ratio="0.5">
    <div class="container">
        <div class="row align-items-center justify-content-center">
            <div class="col-md-10 text-center" data-aos="fade-up">

                <br>
            
                <h1 style="font-size:46px">3D Multimedia</h1>
                <h1 style="font-size:46px">Analytics, Search and Generation</h1>

                <br><br><br>
                <h4> In Conjunction with ICME 2024</h4>
                <h4> 15-19 July, Niagra Falls, Canada</h4>
            </div>
        </div>
    </div>
</div>



<div class="site-section">
    <div class="container">

<!------------------------------ news  ------------------------------------------>


<div class="col-lg-12" id="news" style="padding-top:80px;margin-top:-150px;">
        <h4><i>News</i> !</h4>
        <ul>           
            <li>
                <p style="height: 10px">
                    <strong style="font-size:20px;color:red;font-family:'Times New Roman';"> March 4, 2024:&nbsp;&thinsp;&thinsp;</strong>The website is coming. Call for papers.
                </p>
            </li>                             
        </ul>
</div>
<br><br><br><br>

<!------------------------  overview  ----------------------->
            <div class="col-lg-12">
                <div class="section-title">
                    <h2>Overview</h2>
                    <br>
                    <h4 style="font-size: 21px;"><i></i></h4>
                </div>
                <div class="trend-entry d-flex">
                    <div class="trend-contents">
                        <p>

                            &emsp;&emsp;  Today, ubiquitous multimedia sensors and large-scale computing infrastructures are producing at a rapid velocity of <font face='Times New Roman'>3D</font> multi-modality data, such as <font face='Times New Roman'>3D</font> point cloud acquired with LIDAR sensors, RGB-D videos recorded by Kinect cameras, meshes of varying topology, and volumetric data. <font face='Times New Roman'>3D</font> multimedia combines different content forms such as text, audio, images, and video with <font face='Times New Roman'>3D</font> information, which can perceive the world better since the real world is 3-dimensional instead of 2-dimensional. For example, the robots can manipulate objects successfully by recognizing the object via RGB frames and perceiving the object size via point cloud. Researchers have strived to push the limits of <font face='Times New Roman'>3D</font> multimedia search and generation in various applications, such as autonomous driving, robotic visual navigation, smart industrial manufacturing, logistics distribution, and logistics picking. The <font face='Times New Roman'>3D</font> multimedia (e.g., the videos and point cloud) can also help the agents to grasp, move and place the packages automatically in logistics picking systems.
Therefore, <font face='Times New Roman'>3D</font> multimedia analytics is one of the fundamental problems in multimedia understanding. Different from <font face='Times New Roman'>3D</font> vision, <font face='Times New Roman'>3D</font> multimedia analytics mainly concentrate on fusing the <font face='Times New Roman'>3D</font> content with other media. It is a very challenging problem that involves multiple tasks such as human <font face='Times New Roman'>3D</font> mesh recovery and analysis, <font face='Times New Roman'>3D</font> shapes and scenes generation from real-world data, <font face='Times New Roman'>3D</font> virtual talking head, <font face='Times New Roman'>3D</font> multimedia classification and retrieval, <font face='Times New Roman'>3D</font> semantic segmentation, <font face='Times New Roman'>3D</font> object detection and tracking, <font face='Times New Roman'>3D</font> multimedia scene understanding, and so on. Therefore, the purpose of this workshop is to: 1) bring together the state-of-the-art research on <font face='Times New Roman'>3D</font> multimedia analysis; 2) call for a coordinated effort to understand the opportunities and challenges emerging in <font face='Times New Roman'>3D</font> multimedia analysis; 3) identify key tasks and evaluate the state-of-the-art methods; 4) showcase innovative methodologies and ideas; 5) introduce interesting real-world <font face='Times New Roman'>3D</font> multimedia analysis systems or applications; and 6) propose new real-world or simulated datasets and discuss future directions. We solicit original contributions in all fields of <font face='Times New Roman'>3D</font> multimedia analysis that explore the multi-modality data to generate the strong <font face='Times New Roman'>3D</font> data representation. We believe this workshop will offer a timely collection of research updates to benefit researchers and practitioners in the broad multimedia communities.
                            <br>
                        </p>
                    </div>
                </div>
            </div>
<!------------------------  Call for papers  --------------------->
<div class="col-lg-12" id="call for papers" style="padding-top:80px;margin-top:-80px;">
        <div class="section-title">

            <br><br><br>
            <h2>Call for papers</h2>
        </div>

        <div class="trend-entry d-flex">
                <div class="trend-contents">
                    <p style="margin: auto;">
                        &emsp; &emsp;We invite submissions for ICME <font face='Times New Roman'>2024</font> Workshop, <font face='Times New Roman'>3D</font> Multimedia Analytics, Search and Generation (<font face="Times New Roman">3DMM2024</font>), which brings researchers together to discuss robust, interpretable, and responsible technologies for <font face='Times New Roman'>3D</font> multimedia analysis. We solicit original research and survey papers that must be no longer than <font face="Times New Roman" size=5px>6</font> pages (including all text, figures, and references). Each submitted paper will be peer-reviewed by at least three reviewers. All accepted papers will be presented as either oral or poster presentations, with the best paper award. Papers that violate anonymity, do not use the ICME submission template will be rejected without review. By submitting a manuscript to this workshop, the authors acknowledge that no paper substantially similar in content has been submitted to another workshop or conference during the review period. Authors should prepare their manuscript according to the Guide for Authors of ICME. For detailed instructions, see <a href="https://2024.ieeeicme.org/author-information-and-submission-instructions/" style="font-family: 'Times New Roman', Times, serif; font-size:21px;">here</a>. Submission address is <a href="https://cmt3.research.microsoft.com/ICMEW2024/" style="font-family: 'Times New Roman', Times, serif; font-size:21px;">here</a>. 
                        <br>
                        &emsp;&emsp;The scope of this workshop includes, but is not limited to, the following topics:
                    </p>
                <ul class="set_ul" style="margin-bottom: 0px; margin-left:20px; display: inline-block;">
                        <li>
                            Generative Models for <font face='Times New Roman'>3D</font> Multimedia and <font face='Times New Roman'>3D</font> Multimedia Synthesis
                        </li>
                        <li>
                            Generating <font face='Times New Roman'>3D</font> Multimedia from Real-world Data
                        </li>
                        <li>
                            <font face='Times New Roman'>3D</font> Multimodal Analysis and Description
                        </li>
                        <li>
                            Multimedia Virtual/Augmented Reality
                        </li>
                        <li>
                            <font face='Times New Roman'>3D</font> Multimedia Systems
                        </li>
                        
                        <li>
                            <font face='Times New Roman'>3D</font> Multimedia Search and Recommendation
                        </li>
                       
                        <li>
                            Mobile <font face='Times New Roman'>3D</font> Multimedia
                        </li>
                        <li>
                            <font face='Times New Roman'>3D</font> Shape Estimation and Reconstruction
                        </li>
                        <li>
                            <font face='Times New Roman'>3D</font> Scene and Object Understanding
                        </li>                        
                        
                        <li>
                            High-level Representation of <font face='Times New Roman'>3D</font> Multimedia Data
                        </li>
                        <li>
                            <font face='Times New Roman'>3D</font> Multimedia Application in Industry
                        </li>                                              
                    </ul> 
                    <p style="margin: auto;">
                        &emsp;&emsp;<strong>Fast Review for Rejected Regular Submissions of ICME 2024</strong>
                        <br>
                        &emsp;&emsp;We set up a Fast Review mechanism for the regular submissions rejected by the ICME main conference. We strongly encourage the rejected papers to be submitted to this workshop. In order to submit through Fast Review, authors must write a front letter (1 page) to clarify the revision of the paper and attach all previous reviews. All the papers submitted through Fast Review will be directly reviewed by meta-reviewers to make the decisions.
                    </p>                                      
                </div>
            </div>
    </div>

    



    <!------------------------------ Invited speakers  ------------------------------------------>

<div class="col-lg-12" id="invited speakers" style="padding-top:80px;margin-top:-80px;">
    <div class="section-title">

        <br><br><br>
        <h2>Invited speakers</h2>
        <br><br>
            <!------------------------------ The first speaker info ------------------------------------------>
            <div align="left">
            <div class="instructor_fina" style="float: left; display: inline; margin-top: 1px;">
                <a href="https://cs.pku.edu.cn/info/1236/2106.htm">
                    <div class="instructorphoto"><img src="imgs/SiweiMa_1.jpg"></div>
                </a>
                <div style="font-family:Helvetica, sans-serif; font-size: 17px;display: inline-block;">Prof.</div>
                <a href="https://cs.pku.edu.cn/info/1236/2106.htm">
                    <div style="font-size: 17px;display: inline-block;">&thinsp;Siwei Ma</div>
                </a>
                <div style="font-family:Helvetica, sans-serif; font-size: 17px">Peking University, China. </div>
            </div>  

            <div style="font-family:Times New Roman, sans-serif; font-size: 20px; display: inline-block; width: 78%;text-align: justify;">
                <strong>Title:</strong> 3D Visual Media Representation and Coding.
                <br>
                <strong>Abstract:</strong> The application of 3D immersive media is developing rapidly and has broad prospects. Compared with the traditional 2D visual media such as 2D video, its data volume has doubled, requiring more efficient representation and encoding techniques. This talk mainly introduces the recent progress in efficient representation and encoding technology for 3D visual media, including traditional multi view video, depth video, point cloud, and the recent mesh coding technologies and standards. In addition, it also explores emerging topics such as digital human encoding and neural radiation field compression.
                <br>
                <strong>Biography:</strong> Siwei Ma (Fellow, IEEE) received the B.S. degree from Shandong Normal University, Jinan, China, in 1999, and the Ph.D. degree in computer science from the Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China, in 2005. He was a Post-Doctoral Researcher with the University of Southern California, Los Angeles, CA, USA, from 2005 to 2007. He joined the School of Electronics Engineering and Computer Science, Institute of Digital Media, Peking University, Beijing, where he is currently a Professor . He has authored over 300 technical papers in refereed journals and proceedings in image and video coding, video processing, video streaming, and transmission. He served/serves as an Associate Editor for the IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY, IEEE TRANSACTIONS ON IMAGE PROCESSING and the Journal of Visual Communication and Image Representation. 
            </div>
        </div>
        <!------------------------------ The first speaker info END------------------------------------------>
            
        <br>
        <br>
        <br>
        <br> 
        
        <!------------------------------ Huan Hang ------------------------------------------>
        <div align="left">
            <div class="instructor_fina" style="float: left; display: inline; margin-top: 1px;">
                <a href="https://nlpr.ia.ac.cn/fanbin/">
                    <div class="instructorphoto"><img src="imgs/fanbin.jpg"></div>
                </a>
                <div style="font-family:Helvetica, sans-serif; font-size: 17px;display: inline-block;">Prof.</div>
                <a href="https://nlpr.ia.ac.cn/fanbin/">
                    <div style="font-size: 17px;display: inline-block;">&thinsp;Bin Fan</div>
                </a>
                <div style="font-family:Helvetica, sans-serif; font-size: 17px">University of Science and Technology Beijing, China</div>
            </div>  

            <div style="font-family:Times New Roman, sans-serif; font-size: 20px; display: inline-block; width: 78%;text-align: justify;">
                <strong>Title:</strong> Learning good features for visual localization in known 3D environments
               <br>
                <strong>Abstract:</strong> Perceiving the three-dimensional world is a key issue in fields such as computer vision, human-computer interaction, and robotics. Visual localization is one of the crucial technologies for 3D perception, aiming to calculate the position and orientation of a camera in a 3D scene based on its captured image. Due to its convenience, flexible deployment, and low cost, it is favored by various applications such as autonomous driving, augmented reality, and intelligent robots. Extracting robust image features to establish reliable correspondences across different application environments has become one of the key technologies driving the practical application of visual localization. In this talk, I will introduce some of our work in this area, including Attention Weighted Local Descriptors, Task-Aligned Local Features, GAN-based local features, and Semantic-Aware Local Features.
               <br>
               <strong>Biography:</strong> Bin Fan received PhD degree from the National Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences (CASIA) in 2011. After got his doctoral degree, he had been worked in the NLPR, firstly as an Assistant Professor and then as an Associate Professor until 2020. He is now a full professor in University of Science and Technology Beijing, China. During 2015-2016, he visited the CVLab at EPFL. His research is mainly focused on addressing problems related to image-based 3D perception and analysis, image understanding, etc. He has published over 60 papers in highly ranked conferences and journals, including IEEE TPAMI/TIP/TNNLS/TMM, Pattern Recognition, CVPR, ICCV, ECCV. He serves as Associate Editor of Pattern Recognition, Journal of Visual Communication and Image Representation, AC of CVPR/NeurIPS/ECCV/ICME. He is a Senior member of IEEE since 2016. 
            </div>	

        </div>
         <!------------------------------ Huan Hang ------------------------------------------>
        <br>
        <br>
        <br>
        <br> 

        <!------------------------------ The 3rd speaker info ------------------------------------------>
        <div align="left">
            <div class="instructor_fina" style="float: left; display: inline; margin-top: 1px;">
                <a href="https://www.eng.uwo.ca/research/the-engineers-impact/soodeh-nikan.html">
                    <div class="instructorphoto"><img src="imgs/Nikan.jpg"></div>
                </a>
                <div style="font-family:Helvetica, sans-serif; font-size: 17px;display: inline-block;">Prof.</div>
                <a href="https://www.eng.uwo.ca/research/the-engineers-impact/soodeh-nikan.html">
                    <div style="font-size: 17px;display: inline-block;">&thinsp;Soodeh Nikan</div>
                </a>
                <div style="font-family:Helvetica, sans-serif; font-size: 17px">Western University, Canada. </div>
            </div>  

            <div style="font-family:Times New Roman, sans-serif; font-size: 20px; display: inline-block; width: 78%;text-align: justify;">
                <strong>Title:</strong> Revolutionizing Spatial Intelligence: The Impact of Vision-Language Models on 3D Perception.
               <br>
                <strong>Abstract:</strong> The integration of Vision-Language Models (VLMs) with 3D perception technologies is revolutionizing spatial intelligence, enabling AI systems to understand and interact with their environments in unprecedented ways. This talk will explore the evolution of spatial intelligence and present recent advancements in research. Specifically, I will discuss how VLMs enhance scene understanding and object detection in autonomous driving, improving safety and efficiency. Additionally, the role of VLMs in robotics will be highlighted, where they enhance navigation and human-robot interaction, enabling robots to perform complex tasks with greater precision. In healthcare, I will demonstrate how VLMs assist in accurate diagnosis and analysis of medical images, providing detailed descriptions and identifying abnormalities. The talk will also address current challenges, such as scalability and ethical considerations, including data privacy and fairness. I will propose future directions for responsible AI development, emphasizing the importance of creating robust, interpretable, and ethical AI systems. Attendees will gain insights into cutting-edge VLM research and its potential to revolutionize various industries by providing a deeper, contextual understanding of visual data.
               <br>
               <strong>Biography:</strong> Soodeh Nikan received her Ph.D. in Electrical and Computer Engineering from University of Windsor in 2014. She is currently an Assistant Professor in software engineering at the Department of ECE, Western University, Canada. Her research interests lie in the intersection of artificial intelligence (AI) and various engineering disciplines including computer vision, data analytics, biomedical engineering and signal processing. Dr. Nikan has made significant contributions to optimized deep/machine learning technologies for highly demanding and safety-critical areas. She has an extensive academic and industry portfolio in AI and automotive research through her research on autonomous driving and intelligent transportation at Ford Motor Company and Western University. Her research excellence has been recognized by prestigious awards such as the NSERC and Mitacs awards. Demonstrating her deep commitment to the academic community, Dr. Nikan serves as a Counselor for the IEEE London Ontario Section Branch and actively participates as a reviewer for technical committees and IEEE-sponsored venues and journals. 
            </div>
        </div>
        <!------------------------------ The 3rd speaker info END------------------------------------------>
        
        <br>
        <br>
        <br>
        <br> 
</div>
</div>

<!------------------------------ Invited speakers  END ------------------------------------------>



<!----------------------------  organizers  ---------------------------------------->
<div class="col-lg-12" id="organizers" style="padding-top:80px;margin-top:-80px;">

    <!----------------------------  organizer  ---------------------------------------->
        <div class="section-title">
            <br><br><br>
            <h2>Organizers</h2>
        </div>
    
        <div align="center">

                <!--------------  dai peng --------->
                <div class="instructor_mine">
                    <a href="https://pdaicode.github.io/">
                        <div class="instructorphoto"><img src="imgs/DaiPeng1.jpg"></div>
                        <div style="font-size: 18px">Peng Dai</div>
                    </a>
                    <div style="font-family:Helvetica, sans-serif;font-size: 18px">Noah’s Ark Lab, Canada</div>
                </div>

                <!--------------  an shan  --------->
                <div class="instructor_mine">
                    <a href="https://anshan.ai/">
                        <div class="instructorphoto"><img src="imgs/AnShan.jpg"></div>
                        <div style="font-size: 18px">Shan An</div>
                    </a>
                    <div style="font-family:Helvetica, sans-serif;font-size: 18px">JD Health, China</div>
                </div>

                <!--------------  liu an an  --------->
                <div class="instructor_mine">
                    <a href="https://liuanantju.github.io">
                        <div class="instructorphoto"><img src="imgs/LiuAnAn.png"></div>
                        <div style="font-size: 18px">An-An Liu</div>
                    </a>
                    <div style="font-family:Helvetica, sans-serif;font-size: 18px">Tianjin University, China</div>
                </div>
              
                <!--------------  liukun  --------->
                <div class="instructor">
                    <a href="https://scholar.google.com/citations?user=NMMB7wcAAAAJ&hl=en">
                        <div class="instructorphoto">
                                <img src="imgs/YiboHu.JPG">
                        </div>
                        <div style="font-size: 18px">Kun Liu</div>
                    </a>
                    <div style="font-family:Helvetica, sans-serif;font-size: 18px">Explore Academy of JD.com, China</div>
                </div>         
                

                <!--------------   7 liuwu  --------->
                <div class="instructor_mine">
                    <a href="https://drliuwu.com/">
                        <div class="instructorphoto"><img src="imgs/JinggenLiu.png"></div>
                        <div style="font-size: 18px">Wu Liu</div>
                    </a>
                    <div style="font-family:Helvetica, sans-serif;font-size: 18px">University of Science and Technology of China, China</div>
                </div>
                
        
                <!--------------  8 Antonios Gasteratos   --------->
                <div class="instructor_mine">
                    <a href="https://robotics.pme.duth.gr/antonis/">
                        <div class="instructorphoto"><img src="imgs/Antonios.jpg"></div>
                        <div style="font-size: 18px">Antonios Gasteratos</div>
                    </a>
                    <div style="font-family:Helvetica, sans-serif;font-size: 18px">Democritus University of Thrace, Greece</div>
                </div>
        </div>

        <!----------------------------  Committe Chairs  ---------------------------------------->
       
 
        
    </div>
      


    <!----------------------------  Program Chairs  ---------------------------------------->
<div class="col-lg-12" id="chairs" style="padding-top:80px;margin-top:-80px;">

    <!----------------------------  Program Chairs   ---------------------------------------->
        <div class="section-title">
            <br><br><br>
            <h2>Program Chairs</h2>
        </div>
    
        <div align="center">     
                <!--------------1  Ge Xu Ri --------->
                <div class="instructor">
                    <a href="https://xurige1995.github.io/">
                        <div class="instructorphoto">
                                <img src="imgs/gexuri.png">
                        </div>
                        <div style="font-size: 18px">Xuri Ge</div>
                    </a>
                    <div style="font-family:Helvetica, sans-serif;font-size: 18px">University of Glasgow, UK</div>
                </div> 

                <!--------------2   Ye Jun Jie --------->
                <div class="instructor">
                    <a href="https://jay-ye.github.io/">
                        <div class="instructorphoto">
                                <img src="imgs/yejunjie1.jpg">
                        </div>
                        <div style="font-size: 18px">Junjie Ye</div>
                    </a>
                    <div style="font-family:Helvetica, sans-serif;font-size: 18px">University of Southern California, USA</div>
                </div> 
              
                <!-------------- 3 Chao Zhang   --------->
                <div class="instructor">                    
                        <div class="instructorphoto">
                                <img src="imgs/zhangchao.jpg">
                        </div>
                        <div style="font-size: 18px">Chao Zhang</div>
                    
                    <div style="font-family:Helvetica, sans-serif;font-size: 18px">JD Health, China</div>
                </div> 

                <!-------------- 4 Guoxin Wang   --------->
                <div class="instructor">                    
                        <div class="instructorphoto">
                                <img src="imgs/WangGuoXin.jpg">
                        </div>
                        <div style="font-size: 18px">Guoxin Wang</div>
                    
                    <div style="font-family:Helvetica, sans-serif;font-size: 18px">Zhejiang University, China</div>
                </div> 

                
        </div>

        <!----------------------------  Program Chairs  ---------------------------------------->        
    </div>


<!------------------------  Oral Orders  --------------------->
<div class="col-lg-12" id="Oral" style="padding-top:80px;margin-top:-80px;">
    <div class="section-title">
        <br><br><br>
        <h2>Accepted Papers</h2>
    </div>
    <div class="trend-entry d-flex">
        <table class="table table-striped" style="border-bottom:2px solid #C4C4C4;border-top:2px solid #C4C4C4;width:70%; line-height: 18px;" align="center">
            <thead>
            <!-- <tr style="background-color:#BFEFFF;"> -->
            <tr>
                <th scope="col" style="text-align: center;" width="10%">Oral Order</th> 
                <th scope="col" style="text-align: center;" width="15%">Paper ID</th> 
                <th scope="col" style="text-align: center;" width="75%"> Paper Title</th>
            </tr>
            </thead>
            <tbody>
            <!-- <tr style="background-color:#8BB1D8;"> -->
            <tr style="background-color:#B6CEE7;">    
                <td>1</td>
                <td>8</td>
                <td>Visibility-aware Human Mesh Recovery via Balancing Dense Correspondence and Probability Model</td>
            </tr>
            <tr>
                <td>2</td>
                <td>12</td>
                <td>Dual Attribute-Spatial Relation Alignment For 3D Visual Grounding</td>
            </tr>
            <tr>
                <td>3</td>
                <td>31</td>
                <td>Automatic Malleefowl Mound Detection Using Lidar-Based Ground and Habitat Features With Planar Terrain Modelling</td>
            </tr>
            <tr>
                <td>4</td>
                <td>39</td>
                <td>I3FNet: Instance-aware Feature Fusion for Few-shot Point Cloud Generation from Single Image</td>
            </tr>
            <tr>
                <td>5</td>
                <td>45</td>
                <td>3DMIT: 3D Multi-Modal Instruction Tuning for Scene Understanding</td>
            </tr>           
            <tr>
                <td>6</td>
                <td>88</td>
                <td>Blender-NeRF: A Monocular Dynamic Human Body Explicit Reconstruction and Rendering Method</td>
            </tr>           
            </tbody>            
        </table> 
    </div>
</div>
<!------------------------  Oral Orders END --------------------->
    



<!------------------------------email-------------------------------->
<br><br>
<p style="margin-top:30px;margin-bottom: 60px; text-align: center; font-family: 'Times New Roman', Times, serif; font-size: 24px;">Previous Workshops on 3DMM: <a href="https://3DMM-ICME2022.github.io/" style="font-family: 'Times New Roman', Times, serif; font-size:21px;">3DMM-ICME2022,</a><a href="https://3DMM-ICME2023.github.io/" style="font-family: 'Times New Roman', Times, serif; font-size:21px;"> 3DMM-ICME2023</a> </p> 
<p style="margin-top:30px;margin-bottom: 60px; text-align: center; font-family: 'Times New Roman', Times, serif; font-size: 24px;">If you have any questions, feel free to contact &lt peng [DOT] dai [DOT] ca [AT] ieee.org</p>

<!-------------------------------   boarder  ---------------------------------------->
        <div class="col-lg-12">
            <div style="display:inline-block;width:500px;">
                <script type="text/javascript" src="//rc.rev
            olvermaps.com/0/0/7.js?i=2hlmeh3dic1&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;br=19&amp;sx=0"
                        async="async"></script>
            </div>
        </div>
    </div>
</div>
</div>
<!-- END section -->


<div class="footer">
    <div class="container">
        <div class="row">
            <div class="col-12">
                <div class="copyright">
                    <p>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        Copyright &copy;<script>document.write(new Date().getFullYear());</script>
                        All rights reserved | Powered by <a
                            href="https://colorlib.com" target="_blank">Colorlib</a>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                    </p>
                </div>
            </div>
        </div>
    </div>
</div>


</div>
<!-- .site-wrap -->


<!-- loader -->
<div id="loader" class="show fullscreen">
    <svg class="circular" width="48px" height="48px">
        <circle class="path-bg" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke="#eeeeee"/>
        <circle class="path" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke-miterlimit="10"
                stroke="#ff5e15"/>
    </svg>
</div>

<script src="js/jquery-3.3.1.min.js"></script>
<script src="js/jquery-migrate-3.0.1.min.js"></script>
<script src="js/jquery-ui.js"></script>
<script src="js/popper.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/owl.carousel.min.js"></script>
<script src="js/jquery.stellar.min.js"></script>
<script src="js/jquery.countdown.min.js"></script>
<script src="js/bootstrap-datepicker.min.js"></script>
<script src="js/jquery.easing.1.3.js"></script>
<script src="js/aos.js"></script>
<script src="js/jquery.fancybox.min.js"></script>
<script src="js/jquery.sticky.js"></script>
<script src="js/jquery.mb.YTPlayer.min.js"></script>


<script src="js/main.js"></script>

</body>

</html>
