<!DOCTYPE html>
<html lang="en">

<head>
    <title>3DMM</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

 
    <link rel="icon" type="image/x-ico" href="imgs/logo.png" />
    

    <link href="https://fonts.googleapis.com/css?family=B612+Mono|Cabin:400,700&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="fonts/icomoon/style.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
          integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">

    <link rel="stylesheet" href="css/jquery-ui.css">
    <link rel="stylesheet" href="css/owl.carousel.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">

    <link rel="stylesheet" href="css/jquery.fancybox.min.css">

    <link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">

    <link rel="stylesheet" href="css/aos.css">
    <link href="css/jquery.mb.YTPlayer.min.css" media="all" rel="stylesheet" type="text/css">

    <link rel="stylesheet" href="css/style.css">



    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-88572407-1', 'auto');
        ga('send', 'pageview');
    </script>
</head>

<body data-spy="scroll" data-target=".site-navbar-target" data-offset="300">



<div class="site-wrap">

    <div class="site-mobile-menu site-navbar-target">
        <div class="site-mobile-menu-header">

            <div class="site-mobile-menu-close mt-3">
                <span class="icon-close2 js-menu-toggle"></span>
            </div>
        </div>
        <div class="site-mobile-menu-body"></div>
    </div>

<!---------------------------导航栏------------------------------->
    <div class="site-navbar py-2 js-sticky-header site-navbar-target d-none pl-0 d-lg-block" role="banner" > 


            <div class="d-flex align-items-center">
             

                <div class="mr-auto">

               
                    <nav class="site-navigation position-relative text-right" role="navigation">
                     <a href="http://iccv2021.thecvf.com/"> <img class='iccv' src="imgs/iccv2021.png" width=190px height=47px style="margin-top:-1px;"></a>

               

                        <ul class="site-menu main-menu js-clone-nav mr-auto d-none pl-0 d-lg-block">
                            <li>
                           
                                <a href="index.html"><img src="imgs/logo.png" width=190px height=47px style="margin-left: 200px; margin-top: -3.5px; position: sticky;"></a>
                            </li>
                            <li>
                                
                                <a href="index.html" class="nav-link text-left" style="font-size:15px; font-family:Georgia, serif;">Home</a>
                            </li>
                            
                            <li>
                                <a href="index.html#call for papers" class="nav-link text-left" style="font-size:15px; font-family:Georgia, serif">Call for papers</a>
                            </li>

                            <li>
                                <a href="index.html#dates" class="nav-link text-left" style="font-size:15px; font-family:Georgia, serif">important dates</a>
                            </li>

                            <li>
                                <a href="index.html#invited speakers" class="nav-link text-left" style="font-size:15px; font-family:Georgia, serif">invited speakers</a>
                            </li>



                            <li>
                                <a href="index.html#organizers" class="nav-link text-left" style="font-size:15px; font-family:Georgia, serif">organizers</a>
                            </li>


                            </li>
                        </ul>
                    </nav>

                </div>

            </div>
        </div>

    </div>

</div>

<div class="site-blocks-cover overlay inner-page-cover" style="background-image: url('imgs/background.png');" 


     data-stellar-background-ratio="0.5">
    <div class="container">
        <div class="row align-items-center justify-content-center">
            <div class="col-md-10 text-center" data-aos="fade-up">

                <br>
            
                <h1 style="font-size:46px">3D Multimedia</h1>
                <h1 style="font-size:46px">Analytics, Search and Generation</h1>

                <br><br><br>
                <h4> In Conjunction with ICME 2023</h4>
                <h4> July, Brisbane, Australia</h4>
               
            </div>
        </div>
    </div>
</div>



<div class="site-section">
    <div class="container">

<!------------------------------ news  ------------------------------------------>


<div class="col-lg-12" id="news" style="padding-top:80px;margin-top:-150px;">
        <h4><i>News</i> !</h4>
        <ul>           
            <li>
                <p style="height: 10px">
                    <strong style="font-size:20px;color:red;font-family:'Times New Roman';"> Jan 30, 2023:&nbsp;&thinsp;&thinsp;</strong>The website is coming. Call for papers.
                </p>
            </li> 
            <li>
                <p style="height: 10px">
                    <strong style="font-size:20px;color:red;font-family:'Times New Roman';"> May 1, 2023:&nbsp;&thinsp;&thinsp;</strong>Six papers are accepted. Congratulations to the authors.
                </p>
            </li>                  
            <li>
                <p style="height: 10px">                    
                    <strong style="font-size:20px;color:red;font-family:'Times New Roman';"> June 5, 2023:&nbsp;&thinsp;&thinsp;</strong>We are honored to invite <a href="http://seea.tju.edu.cn/info/1014/1451.htm" style="font-family: 'Times New Roman', Times, serif; font-size:21px;">Prof. Weizhi Nie</a> to give a keynote.
                </p>
            </li>  
            <li>
                <p style="height: 10px">                    
                    <strong style="font-size:20px;color:red;font-family:'Times New Roman';"> June 12, 2023:&nbsp;&thinsp;&thinsp;</strong>We are honored to invite <a href="http://tingyao.deepfun.club" style="font-family: 'Times New Roman', Times, serif; font-size:21px;">Dr. Ting Yao</a> to give a keynote.
                </p>
            </li>     
            <li>
                <p style="height: 10px">                    
                    <strong style="font-size:20px;color:red;font-family:'Times New Roman';"> June 20, 2023:&nbsp;&thinsp;&thinsp;</strong>We are honored to invite <a href="https://zhpcui.github.io" style="font-family: 'Times New Roman', Times, serif; font-size:21px;">Prof. Zhaopeng Cui</a> to give a keynote.
                </p>
            </li>                 
        </ul>
</div>
<br><br><br><br>

<!------------------------  overview  ----------------------->
            <div class="col-lg-12">
                <div class="section-title">
                    <h2>Overview</h2>
                    <br>
                    <h4 style="font-size: 21px;"><i></i></h4>
                </div>
                <div class="trend-entry d-flex">
                    <div class="trend-contents">
                        <p>

                            &emsp;&emsp;  Today, ubiquitous multimedia sensors and large-scale computing infrastructures are producing at a rapid velocity of <font face='Times New Roman'>3D</font> multi-modality data, such as <font face='Times New Roman'>3D</font> point cloud acquired with LIDAR sensors, RGB-D videos recorded by Kinect cameras, meshes of varying topology, and volumetric data. <font face='Times New Roman'>3D</font> multimedia combines different content forms such as text, audio, images, and video with <font face='Times New Roman'>3D</font> information, which can perceive the world better since the real world is 3-dimensional instead of 2-dimensional. For example, the robots can manipulate objects successfully by recognizing the object via RGB frames and perceiving the object size via point cloud. Researchers have strived to push the limits of <font face='Times New Roman'>3D</font> multimedia search and generation in various applications, such as autonomous driving, robotic visual navigation, smart industrial manufacturing, logistics distribution, and logistics picking. The <font face='Times New Roman'>3D</font> multimedia (e.g., the videos and point cloud) can also help the agents to grasp, move and place the packages automatically in logistics picking systems.
Therefore, <font face='Times New Roman'>3D</font> multimedia analytics is one of the fundamental problems in multimedia understanding. Different from <font face='Times New Roman'>3D</font> vision, <font face='Times New Roman'>3D</font> multimedia analytics mainly concentrate on fusing the <font face='Times New Roman'>3D</font> content with other media. It is a very challenging problem that involves multiple tasks such as human <font face='Times New Roman'>3D</font> mesh recovery and analysis, <font face='Times New Roman'>3D</font> shapes and scenes generation from real-world data, <font face='Times New Roman'>3D</font> virtual talking head, <font face='Times New Roman'>3D</font> multimedia classification and retrieval, <font face='Times New Roman'>3D</font> semantic segmentation, <font face='Times New Roman'>3D</font> object detection and tracking, <font face='Times New Roman'>3D</font> multimedia scene understanding, and so on. Therefore, the purpose of this workshop is to: 1) bring together the state-of-the-art research on <font face='Times New Roman'>3D</font> multimedia analysis; 2) call for a coordinated effort to understand the opportunities and challenges emerging in <font face='Times New Roman'>3D</font> multimedia analysis; 3) identify key tasks and evaluate the state-of-the-art methods; 4) showcase innovative methodologies and ideas; 5) introduce interesting real-world <font face='Times New Roman'>3D</font> multimedia analysis systems or applications; and 6) propose new real-world or simulated datasets and discuss future directions. We solicit original contributions in all fields of <font face='Times New Roman'>3D</font> multimedia analysis that explore the multi-modality data to generate the strong <font face='Times New Roman'>3D</font> data representation. We believe this workshop will offer a timely collection of research updates to benefit researchers and practitioners in the broad multimedia communities.
                            <br>
                        </p>
                    </div>
                </div>
            </div>
<!------------------------  Call for papers  --------------------->
<div class="col-lg-12" id="call for papers" style="padding-top:80px;margin-top:-80px;">
        <div class="section-title">

            <br><br><br>
            <h2>Call for papers</h2>
        </div>

        <div class="trend-entry d-flex">
                <div class="trend-contents">
                    <p style="margin: auto;">
                        &emsp; &emsp;We invite submissions for ICME <font face='Times New Roman'>2023</font> Workshop, <font face='Times New Roman'>3D</font> Multimedia Analytics, Search and Generation (<font face="Times New Roman">3DMM2023</font>), which brings researchers together to discuss robust, interpretable, and responsible technologies for <font face='Times New Roman'>3D</font> multimedia analysis. We solicit original research and survey papers that must be no longer than <font face="Times New Roman" size=5px>6</font> pages (including all text, figures, and references). Each submitted paper will be peer-reviewed by at least three reviewers. All accepted papers will be presented as either oral or poster presentations, with the best paper award. Papers that violate anonymity, do not use the ICME submission template will be rejected without review. By submitting a manuscript to this workshop, the authors acknowledge that no paper substantially similar in content has been submitted to another workshop or conference during the review period. Authors should prepare their manuscript according to the Guide for Authors of ICME. The paper submission link is at <a href="https://cmt3.research.microsoft.com/ICMEW2023" style="font-family: 'Times New Roman', Times, serif; font-size:21px;">here</a>. For detailed instructions, see <a href="http://2023.ieeeicme.org/" style="font-family: 'Times New Roman', Times, serif; font-size:21px;">here</a>.
                        <br>
                        &emsp;&emsp;The scope of this workshop includes, but is not limited to, the following topics:
                    </p>
                <ul class="set_ul" style="margin-bottom: 0px; margin-left:20px; display: inline-block;">
                        <li>
                            Generative Models for <font face='Times New Roman'>3D</font> Multimedia and <font face='Times New Roman'>3D</font> Multimedia Synthesis
                        </li>
                        <li>
                            Generating <font face='Times New Roman'>3D</font> Multimedia from Real-world Data
                        </li>
                        <li>
                            <font face='Times New Roman'>3D</font> Multimodal Analysis and Description
                        </li>
                        <li>
                            Multimedia Virtual/Augmented Reality
                        </li>
                        <li>
                            <font face='Times New Roman'>3D</font> Multimedia Systems
                        </li>
                        
                        <li>
                            <font face='Times New Roman'>3D</font> Multimedia Search and Recommendation
                        </li>
                       
                        <li>
                            Mobile <font face='Times New Roman'>3D</font> Multimedia
                        </li>
                        <li>
                            <font face='Times New Roman'>3D</font> Shape Estimation and Reconstruction
                        </li>
                        <li>
                            <font face='Times New Roman'>3D</font> Scene and Object Understanding
                        </li>                        
                        
                        <li>
                            High-level Representation of <font face='Times New Roman'>3D</font> Multimedia Data
                        </li>
                        <li>
                            <font face='Times New Roman'>3D</font> Multimedia Application in Industry
                        </li>                                              
                    </ul>

                    <p style="margin: auto;">
                        &emsp;&emsp;<strong>Fast Review for Rejected Regular Submissions of ICME 2023</strong>
                        <br>
                        &emsp;&emsp;We set up a Fast Review mechanism for the regular submissions rejected by the ICME main conference. We strongly encourage the rejected papers to be submitted to this workshop. In order to submit through Fast Review, authors must write a front letter (1 page) to clarify the revision of the paper and attach all previous reviews. All the papers submitted through Fast Review will be directly reviewed by meta-reviewers to make the decisions.
                    </p>

                </div>
            </div>
    </div>

    
<!------------------------  import dates  --------------------->

<div class="col-lg-12" id="dates" style="padding-top:80px;margin-top:-80px;">
        <div class="section-title">

            <br><br><br>
            <h2>Important Dates</h2>
        </div>
        <div class="trend-entry d-flex">
            <table class="table table-striped" style="border-bottom:2px solid #C4C4C4;border-top:2px solid #C4C4C4;width:60%; line-height: 12px;" align="center">
                <thead>
                <!-- <tr style="background-color:#BFEFFF;"> -->
                <tr>
                    <th scope="col" style="text-align: center;"> Description</th>
                    <th scope="col" style="text-align: center;"> Date</th>
                </tr>
                </thead>
                <tbody>
                <!-- <tr style="background-color:#8BB1D8;"> -->
                <tr style="background-color:#B6CEE7;">    
                    <td >Paper Submission Deadline</td>
                    <td>April 1,2023</td>
                </tr>
                <tr>
                    <td >Notification of Acceptance</td>
                    <td>April 23, 2023</td>
                </tr>
                <tr>
                    <td>Camera-Ready Due Date</td>
                    <td>May 1, 2023</td>
                </tr>
                <tr>
                    <td>Workshop Date</td>
                    <td>14 July, 2023</td>
                </tr>

                </tbody>
                
            </table> 
        </div>
</div>


<!------------------------  Workshop Agendas  --------------------->

<div class="col-lg-12" id="agendas" style="padding-top:80px;margin-top:-80px;">
    <div class="section-title">
        <br><br><br>
        <h2>Workshop Agenda</h2>
    </div>
    <div class="trend-entry d-flex">
        <table class="table table-striped" style="border-bottom:2px solid #C4C4C4;border-top:2px solid #C4C4C4;width:70%; line-height: 18px;" align="center">
            <thead>
            <!-- <tr style="background-color:#BFEFFF;"> -->
            <tr>
                <th scope="col" style="text-align: center;">Date</th>
                <th scope="col" style="text-align: center;"> Description</th>
            </tr>
            </thead>
            <tbody>
            <!-- <tr style="background-color:#8BB1D8;"> -->
            <tr style="background-color:#B6CEE7;">    
                <td >8:30-8:40 </td>
                <td>Opening</td>
            </tr>
            <tr>
                <td >8:40-9:20</td>
                <td>Keynote 1: 3D Generation via Memory Knowledge</td>
            </tr>
            <!--  <td height="25px">9:20-10:00 </td>   class="AutoNewline" -->
            <tr>
                <td >9:20-10:00 </td>                
                <td >Keynote 2: Cross-Modal Vision-and-Language Intelligence: Methodologies and Applications</td>
            </tr>
            <tr>
                <td>10:00-10:30</td>
                <td>Tea Break</td>
            </tr>
            <tr>
                <td >10:30-11:00</td>
                <td >Keynote 3: 3D Perception and Understanding with Compositional Neural Radiance Fields</td>
            </tr>

            <tr>
                <td>11:00-12:00</td>
                <td>6 Oral Presentation (~10min * 6)</td>
            </tr>           
            <tr>
                <td>12:00-12:10</td>
                <td> Announce the Best Paper Award, Discussion and Closing</td>
            </tr>            
            </tbody>
            
        </table> 
    </div>
</div>

<tr>
    <td></td>
    <td></td>
</tr>




<!------------------------------ Invited speakers  ------------------------------------------>

<div class="col-lg-12" id="invited speakers" style="padding-top:80px;margin-top:-80px;">
    <div class="section-title">

        <br><br><br>
        <h2>Invited speakers</h2>
        <br><br>
     
        <div align="left">
            <div class="instructor_fina" style="float: left; display: inline; margin-top: 1px;">
                <a href="http://seea.tju.edu.cn/info/1014/1451.htm">
                    <div class="instructorphoto"><img src="imgs/WeizhiNie.jpg"></div>
                </a>
                <div style="font-family:Helvetica, sans-serif; font-size: 17px;display: inline-block;">Prof.</div>
                <a href="http://seea.tju.edu.cn/info/1014/1451.htm">
                    <div style="font-size: 17px;display: inline-block;">&thinsp;Weizhi Nie</div>
                </a>
                <div style="font-family:Helvetica, sans-serif; font-size: 17px">Tianjin University, China</div>
            </div>  

            <div style="font-family:Times New Roman, sans-serif; font-size: 20px; display: inline-block; width: 78%;text-align: justify;">
                <strong>Title:</strong> 3D Generation via Memory Knowledge
               <br>
                <strong>Abstract:</strong> In recent times, the rapid growth of AIGC techonology has led to the release of numerous applications on various websites. These applications primarily involve the generation of textual and visual content. Additionally, the field of 3D generation poses significant challenges, as there are currently no well-established tools available. Compared to text and image content generation models, 3D models contain richer structural and depth information, presenting greater challenges in terms of accuracy and practical application of the generated content. In this report, I will explore the significant contributions of prior knowledge and memory networks in model generation. Furthermore, I will discuss the improvements achieved through this approach in three key aspects: 3D reconstruction, model generation, and point cloud completion. Finally, I would like to engage in a discussion with you regarding the utilization of large-scale models in 3D generation tasks.
               <br>
               <strong>Biography:</strong> Weizhi Nie received the Ph.D degree from Tianjin University, Tianjin, China, in 2015. From 2012 to 2013, he visited the National University of Singapore as a joint Ph.D student. He is currently an associate professor with the school of electrical and information engineering, Tianjin University. His current research interests include 3D model retrieval, 3D generation, multimedia information processing, and analysis. He is currently the Associate Editor of Multimedia Tools and Applications. He regularly serves as a PC member and an invited reviewer for top-tier conferences and prestigious journals in multimedia and artificial intelligence, like ACM Multimedia, IJCAI, AAAI, CVPR, and ICCV. 
            </div>	

        </div>
         <!------------------------------ Huan Hang ------------------------------------------>
        <br>
        <br>
        <br>
        <br> 

        <!------------------------------ The second speaker info ------------------------------------------>
        <div align="left">
            <div class="instructor_fina" style="float: left; display: inline; margin-top: 1px;">
                <a href="http://tingyao.deepfun.club">
                    <div class="instructorphoto"><img src="imgs/TingYao.jpg"></div>
                </a>
                <div style="font-family:Helvetica, sans-serif; font-size: 17px;display: inline-block;">Dr.</div>
                <a href="http://tingyao.deepfun.club">
                    <div style="font-size: 17px;display: inline-block;">&thinsp;Ting Yao</div>
                </a>
                <div style="font-family:Helvetica, sans-serif; font-size: 17px">HiDream.ai, China</div>
            </div>  

            <div style="font-family:Times New Roman, sans-serif; font-size: 20px; display: inline-block; width: 78%;text-align: justify;">
                <strong>Title:</strong> Cross-Modal Vision-and-Language Intelligence: Methodologies and Applications
               <br>
                <strong>Abstract:</strong> Vision and language are two fundamental systems of human representation. Integrating the two in one intelligent system has long been an ambition in multimedia and vision fields, supporting the uniquely cross-modal vision-and-language intelligence. In between, vision to language is capable of describing what the intelligent system see, and language to vision is able to create visual content according to the language inputs. In this talk, we first look into the problem of vision to language, according to the development context of Independency (enhance visual encoder), interaction (boost encoder-decoder with interaction), and symbiosis (learn a universal encoder-decoder as foundation model) between different modalities. Moreover, we present how to efficiently utilize cross-modal foundation model to strengthen language to vision tasks. Finally, we will discuss the practical applications of vision-and-language intelligence in real-world scenarios.
               <br>
               <strong>Biography:</strong> Ting Yao is currently the Co-Founder and CTO of HiDream.ai, a high-tech startup company focusing on generative intelligence for creativity. Previously, he was a Principal Researcher with JD AI Research in Beijing, China and a Researcher with Microsoft Research Asia in Beijing, China. Dr. Yao has co-authored more than 100 peer-reviewed papers in top-notch conferences/journals, with 12,000+ citations. He has developed one standard 3D Convolutional Neural Network, i.e., Pseudo-3D Residual Net, for video understanding, and his video-to-text dataset of MSR-VTT has been used by 400+ institutes worldwide. He serves as an associate editor of IEEE Transactions on Multimedia, Pattern Recognition Letters, and Multimedia Systems. His works have led to many awards, including 2015 ACM-SIGMM Outstanding Ph.D. Thesis Award, 2019 ACM-SIGMM Rising Star Award, 2019 IEEE-TCMC Rising Star Award, 2022 IEEE ICME Multimedia Star Innovator Award, and the winning of 10+ championship in worldwide competitions.
            </div>
        </div>
        <!------------------------------ The second speaker info END------------------------------------------>
        <!------------------------------ Huan Hang ------------------------------------------>
        <br>
        <br>
        <br>
        <br> 
        <!------------------------------ The 3th speaker info ------------------------------------------>
        <div align="left">
            <div class="instructor_fina" style="float: left; display: inline; margin-top: 1px;">
                <a href="https://zhpcui.github.io">
                    <div class="instructorphoto"><img src="imgs/ZhaopengCui.jpg"></div>
                </a>
                <div style="font-family:Helvetica, sans-serif; font-size: 17px;display: inline-block;">Prof.</div>
                <a href="https://zhpcui.github.io/">
                    <div style="font-size: 17px;display: inline-block;">&thinsp;Zhaopeng Cui</div>
                </a>
                <div style="font-family:Helvetica, sans-serif; font-size: 17px">Zhejiang University, China</div>
            </div>  

            <div style="font-family:Times New Roman, sans-serif; font-size: 20px; display: inline-block; width: 78%;text-align: justify;">
                <strong>Title:</strong> 3D Perception and Understanding with Compositional Neural Radiance Fields
                <br>
                <strong>Abstract:</strong> Neural-based 3D modeling and rendering methods, represented by Neural Radiance Fields (NeRF), have recently received extensive attention in fields such as computer vision and graphics. In comparison to traditional explicit point cloud or mesh-based representations, neural representations have shown increased success in detail expression, model compactness, and realistic rendering. However, these implicit representations cannot be directly applied to other 3D tasks. In this talk, we will first introduce how to learn compositional neural radiance fields that can enable tasks such as 3D editing and photo extrapolation. Next, we will present a new paradigm of amodal 3D scene understanding using compositional neural radiance fields that enables reliable 3D understanding from a panoramic image of a closed environment. Finally, we will discuss the application of neural radiance fields for online 3D perception.
                <br>
                <strong>Biography:</strong> Zhaopeng Cui received his Ph.D. degree from Simon Fraser University in 2017 and worked as a senior researcher at ETH Zurich from 2017 to 2020. He is currently a research professor in the College of Computer Science, Zhejiang University. His research interests include 3D mapping and localization, 3D scene understanding, visual navigation, image and video editing. He is currently the associate editor of The Visual Computer. He has served as the associate editor for IROS and senior PC member for AAAI and IJCAI.
            </div>
        </div>
        <!------------------------------ The 3th speaker info END------------------------------------------>

</div>
</div>

<!------------------------------ Invited speakers  END ------------------------------------------>




<!----------------------------  organizers  ---------------------------------------->
<div class="col-lg-12" id="organizers" style="padding-top:80px;margin-top:-80px;">

    <!----------------------------  organizer  ---------------------------------------->
        <div class="section-title">
            <br><br><br>
            <h2>organizers</h2>
        </div>
    
        <div align="center">
            
                <!--------------  an shan  --------->
                <div class="instructor_mine">
                    <a href="https://anshan.ai/">
                        <div class="instructorphoto"><img src="imgs/AnShan.jpg"></div>
                        <div style="font-size: 18px">Shan An</div>
                    </a>
                    <div style="font-family:Helvetica, sans-serif;font-size: 18px">JD Health, China</div>
                </div>

                <!--------------  liu an an  --------->
                <div class="instructor_mine">
                    <a href="https://liuanantju.github.io">
                        <div class="instructorphoto"><img src="imgs/LiuAnAn.png"></div>
                        <div style="font-size: 18px">An-An Liu</div>
                    </a>
                    <div style="font-family:Helvetica, sans-serif;font-size: 18px">Tianjin University, China</div>
                </div>
              
                <!--------------  liukun  --------->
                <div class="instructor">
                    <a href="https://scholar.google.com/citations?user=NMMB7wcAAAAJ&hl=en">
                        <div class="instructorphoto">
                                <img src="imgs/YiboHu.JPG">
                        </div>
                        <div style="font-size: 18px">Kun Liu</div>
                    </a>
                    <div style="font-family:Helvetica, sans-serif;font-size: 18px">JD Logistics, China</div>
                </div>  
                <!--------------  Zhao Na  --------->
                <div class="instructor">
                    <a href="https://na-z.github.io/">
                        <div class="instructorphoto">
                                <img src="imgs/ZhaoNa.png">
                        </div>
                        <div style="font-size: 18px">Na Zhao</div>
                    </a>
                    <div style="font-family:Helvetica, sans-serif;font-size: 18px">Singapore University of Technology and Design, Singapore</div>
                </div> 
              
                <!--------------  Guoxin Wang   --------->
                <div class="instructor">                    
                        <div class="instructorphoto">
                                <img src="imgs/WangGuoXin.jpg">
                        </div>
                        <div style="font-size: 18px">Guoxin Wang</div>
                    
                    <div style="font-family:Helvetica, sans-serif;font-size: 18px">Zhejiang University, China</div>
                </div> 

                <!--------------  liuwu  --------->
                <div class="instructor_mine">
                    <a href="https://drliuwu.com/">
                        <div class="instructorphoto"><img src="imgs/JinggenLiu.png"></div>
                        <div style="font-size: 18px">Wu Liu</div>
                    </a>
                    <div style="font-family:Helvetica, sans-serif;font-size: 18px">Explore Academy of JD.com, China</div>
                </div>
                
        
                <!--------------  Antonios Gasteratos   --------->
                <div class="instructor_mine">
                    <a href="https://robotics.pme.duth.gr/antonis/">
                        <div class="instructorphoto"><img src="imgs/Antonios.jpg"></div>
                        <div style="font-size: 18px">Antonios Gasteratos</div>
                    </a>
                    <div style="font-family:Helvetica, sans-serif;font-size: 18px">Democritus University of Thrace, Greece</div>
                </div>
        </div>

        <!----------------------------  Committe Chairs  ---------------------------------------->
       
 
        
    </div>
      


        
<!------------------------  Oral Orders  --------------------->
<div class="col-lg-12" id="Oral" style="padding-top:80px;margin-top:-80px;">
    <div class="section-title">
        <br><br><br>
        <h2>Accepted Papers</h2>
    </div>
    <div class="trend-entry d-flex">
        <table class="table table-striped" style="border-bottom:2px solid #C4C4C4;border-top:2px solid #C4C4C4;width:70%; line-height: 18px;" align="center">
            <thead>
            <!-- <tr style="background-color:#BFEFFF;"> -->
            <tr>
                <th scope="col" style="text-align: center;" width="25%">Paper ID</th> 
                <th scope="col" style="text-align: center;" width="75%"> Paper Title</th>
            </tr>
            </thead>
            <tbody>
            <!-- <tr style="background-color:#8BB1D8;"> -->
            <tr style="background-color:#B6CEE7;">    
                <td>26</td>
                <td>PointHGN: Point Heterogeneous Graph Neural Network for Point Cloud Learning</td>
            </tr>
            <tr>
                <td>31</td>
                <td>Expressive Speech-driven Facial Animation with Controllable Emotions</td>
            </tr>
            <tr>
                <td>32</td>
                <td>A Simple Masked Autoencoder Paradigm for Point Cloud</td>
            </tr>
            <tr>
                <td>100</td>
                <td>An Algorithm of Three-dimensional Shape Dissection with Mesh Reconstruction</td>
            </tr>
            <tr>
                <td>109</td>
                <td>Video Background Music Recommendation Based on Multi-level Fusion Features</td>
            </tr>           
            <tr>
                <td>117</td>
                <td>PCaSM: Text-Guided composed Image Retrieval with Parallel Content and Style Modules</td>
            </tr>           
            </tbody>            
        </table> 
    </div>
</div>

<!------------------------  Oral Orders END --------------------->



<!------------------------------email-------------------------------->
<br><br>
<p style="margin-top:30px;margin-bottom: 60px; text-align: center; font-family: 'Times New Roman', Times, serif; font-size: 24px;">Previous Workshop on 3DMM: <a href="https://3DMM-ICME2022.github.io/" style="font-family: 'Times New Roman', Times, serif; font-size:21px;">3DMM-ICME2022</a> </p> 
<p style="margin-top:30px;margin-bottom: 60px; text-align: center; font-family: 'Times New Roman', Times, serif; font-size: 24px;">If you have any questions, feel free to contact &lt anshan [DOT] tju [AT] gmail [DOT] com &gt </p>

<!-------------------------------   boarder  ---------------------------------------->
        <div class="col-lg-12">
            <div style="display:inline-block;width:500px;">
                <script type="text/javascript" src="//rc.rev
            olvermaps.com/0/0/7.js?i=2hlmeh3dic1&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;br=19&amp;sx=0"
                        async="async"></script>
            </div>
        </div>
    </div>
</div>
</div>
<!-- END section -->


<div class="footer">
    <div class="container">
        <div class="row">
            <div class="col-12">
                <div class="copyright">
                    <p>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        Copyright &copy;<script>document.write(new Date().getFullYear());</script>
                        All rights reserved | Powered by <a
                            href="https://colorlib.com" target="_blank">Colorlib</a>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                    </p>
                </div>
            </div>
        </div>
    </div>
</div>


</div>
<!-- .site-wrap -->


<!-- loader -->
<div id="loader" class="show fullscreen">
    <svg class="circular" width="48px" height="48px">
        <circle class="path-bg" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke="#eeeeee"/>
        <circle class="path" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke-miterlimit="10"
                stroke="#ff5e15"/>
    </svg>
</div>

<script src="js/jquery-3.3.1.min.js"></script>
<script src="js/jquery-migrate-3.0.1.min.js"></script>
<script src="js/jquery-ui.js"></script>
<script src="js/popper.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/owl.carousel.min.js"></script>
<script src="js/jquery.stellar.min.js"></script>
<script src="js/jquery.countdown.min.js"></script>
<script src="js/bootstrap-datepicker.min.js"></script>
<script src="js/jquery.easing.1.3.js"></script>
<script src="js/aos.js"></script>
<script src="js/jquery.fancybox.min.js"></script>
<script src="js/jquery.sticky.js"></script>
<script src="js/jquery.mb.YTPlayer.min.js"></script>


<script src="js/main.js"></script>

</body>

</html>
